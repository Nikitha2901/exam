{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1502bfeb",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 14th of June 2023, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "* I (Benny) will visit the exam room at around 10:30 to see if there are any questions.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b708db5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"XXX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fcf1c7",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140af589",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "A courier company operates a fleet of delivery trucks that make deliveries to different parts of the city. The trucks are equipped with GPS tracking devices that record the location of each truck at regular intervals. The locations are divided into three regions: downtown, the suburbs, and the countryside. The following table shows the probabilities of a truck transitioning between these regions at each time step:\n",
    "\n",
    "| Current region | Probability of transitioning to downtown | Probability of transitioning to the suburbs | Probability of transitioning to the countryside |\n",
    "|----------------|--------------------------------------------|-----------------------------------------------|------------------------------------------------|\n",
    "| Downtown       | 0.3                                      | 0.4                                           | 0.3                                            |\n",
    "| Suburbs        | 0.2                                      | 0.5                                           | 0.3                                            |\n",
    "| Countryside    | 0.4                                      | 0.3                                           | 0.3                                            |\n",
    "\n",
    "1. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region after two time steps? [2p]\n",
    "2. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region **the first time** after two time steps? [2p]\n",
    "3. Is this Markov chain irreducible? Explain your answer. [3p]\n",
    "4. What is the stationary distribution? [3p]\n",
    "5. Advanced question: What is the expected number of steps until the first time one enters the suburbs region having started in the downtown region. Hint: to get within 1 decimal point, it is enough to compute the probabilities for hitting times below 30. Motivate your answer in detail [4p]. You could also solve this question by simulation, but this gives you a maximum of [2p].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f5fc8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Fill in the answer to part 1 below\n",
    "problem1_p1 = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ca879",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# Fill in the answer to part 2 below\n",
    "problem1_p2 = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4468088",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Fill in the answer to part 3 below as a boolean\n",
    "problem1_irreducible = True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf617c3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Part 3\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 3 below this line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404e5f5",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Fill in the answer to part 4 below\n",
    "# the answer should be a numpy array of length 3\n",
    "# make sure that the entries sums to 1!\n",
    "problem1_stationary = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebfa71e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1144402618.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_7350/1144402618.py\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    expected_steps_to_enter_suburbsIn this section, we initialize the transition matrix P, which represents the probabilities of transitioning between different regions. The element P[0, 1] corresponds to the probability of transitioning from downtown to suburbs.\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Part 5\n",
    "\n",
    "# Fill in the answer to part 5 below\n",
    "# That is, the expected number of steps\n",
    "problem1_ET = XXX\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Given transition matrix\n",
    "P = np.array([[0.3, 0.4, 0.3], [0.2, 0.5, 0.3], [0.4, 0.3, 0.3]])\n",
    "\n",
    "# Probability of entering suburbs from downtown\n",
    "prob_enter_suburbs_from_downtown = P[0, 1]\n",
    "\n",
    "# Expected number of steps until the first time entering suburbs\n",
    "expected_steps_to_enter_suburbs = 1 / prob_enter_suburbs_from_downtown\n",
    "\n",
    "expected_steps_to_enter_suburbsIn this section, we initialize the transition matrix P, which represents the probabilities of transitioning between different regions. The element P[0, 1] corresponds to the probability of transitioning from downtown to suburbs.\n",
    "\n",
    "\n",
    "In this section, we initialize the transition matrix P, which represents the probabilities of transitioning between different regions. The element P[0, 1] corresponds to the probability of transitioning from downtown to suburbs.\n",
    "Here, we use the formula for the expected number of steps until the first time entering suburbs from downtown. This is calculated as the reciprocal of the probability of transitioning from downtown to suburbs. The result is stored in the variable expected_steps_to_enter_suburbs.\n",
    "\n",
    "Now, let's interpret the result:\n",
    "\n",
    "The prob_enter_suburbs_from_downtown is the probability of moving from downtown to suburbs in one step.\n",
    "The expected_steps_to_enter_suburbs is the expected number of steps it takes to enter the suburbs starting from downtown.\n",
    "In this specific scenario, the expected number of steps until the first time entering the suburbs from downtown is a measure of how long, on average, it takes for a truck starting in downtown to reach the suburbs for the first time. This calculation assumes a Markov chain model for the truck's movement between different regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb77a62",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Part 5\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3612800",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006eb1b6",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "You are given the \"Abalone\" dataset found in `data/abalone.csv`, which contains physical measurements of abalone (a type of sea shells) and the age of the abalone measured in **rings** (the number of rings in the shell) [https://en.wikipedia.org/wiki/Abalone](https://en.wikipedia.org/wiki/Abalone). Your task is to train a `linear regression` model to predict the age (Rings) of an abalone based on its physical measurements.\n",
    "\n",
    "To evaluate your model, you will split the dataset into a training set and a testing set. You will use the training set to train your model, and the testing set to evaluate its performance.\n",
    "\n",
    "1. Load the data into a pandas dataframe `problem2_df`. Based on the column names, figure out what are the features and the target and fill in the answer in the correct cell below. [2p]\n",
    "2. Split the data into train and test. [2p]\n",
    "3. Train the model. [1p]\n",
    "4. On the test set, evaluate the model by computing the mean absolute error and plot the empirical distribution function of the residual with confidence bands (i.e. using the DKW inequality and 95% confidence). Hint: you can use the function `plotEDF,makeEDF` combo from `Utils.py` that we have used numerous times, which also contains the option to have confidence bands. [3p]\n",
    "5. Provide a scatter plot where the x-axis corresponds to the predicted value and the y-axis is the true value, do this over the test set. [2p]\n",
    "6. Reason about the performance, for instance, is the value of the mean absolute error good/bad and what do you think about the scatter plot in point 5? [3p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad9ee5",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Let problem2_df be the pandas dataframe that contains the data from the file\n",
    "# data/abalone.csv\n",
    "problem2_df = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6e330",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "\n",
    "problem2_features = [\"XXX\"]\n",
    "\n",
    "# Fill in the target as a string with the correct column name\n",
    "\n",
    "problem2_target = \"XXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614db4e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "problem2_X_train,problem2_X_test,problem2_y_train,problem2_y_test = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10349b69",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Include the necessary imports\n",
    "\n",
    "# Initialize your linear regression model\n",
    "problem2_model = XXX\n",
    "\n",
    "# Train your model on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf8286",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Evaluate the model by computing the mean absolute error \n",
    "problem2_mae = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247ee5e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Write the code to plot the empirical distribution function of the residual\n",
    "# with confidence bands with 95% confidence in this cell\n",
    "\n",
    "# from Utils import makeEDF,plotEDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76a549",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "# Write the code below to produce the scatter plot for part 5\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from Utils import plotEDF, makeEDF\n",
    "\n",
    "# Step 1: Load the data into a pandas dataframe\n",
    "problem2_df = pd.read_csv(\"data/abalone.csv\")\n",
    "\n",
    "# Identify features and target based on column names\n",
    "features = problem2_df.drop(\"Rings\", axis=1)  # Assuming \"Rings\" is the target\n",
    "target = problem2_df[\"Rings\"]\n",
    "\n",
    "# Step 2: Split the data into train and test\n",
    "train_data, test_data, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_data, train_target)\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "predictions = model.predict(test_data)\n",
    "mae = mean_absolute_error(test_target, predictions)\n",
    "\n",
    "# Plot the empirical distribution function with confidence bands\n",
    "edf, x_values, confidence_bands = makeEDF(predictions - test_target, alpha=0.05)\n",
    "plotEDF(edf, x_values, confidence_bands, xlabel=\"Residuals\", title=\"Empirical Distribution Function with Confidence Bands\")\n",
    "\n",
    "# Step 5: Provide a scatter plot of predicted vs true values on the test set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(predictions, test_target, alpha=0.5)\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"True Values\")\n",
    "plt.title(\"Scatter Plot of Predicted vs True Values on Test Set\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Reason about the performance\n",
    "# Evaluate Mean Absolute Error\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Analyze the scatter plot and discuss the model's performance\n",
    "# - Check if the points are close to the diagonal (indicating good predictions)\n",
    "# - Observe if there are patterns or outliers\n",
    "# - Discuss the overall fit of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8067e69",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "## Part 6\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 6 below this line.\n",
    "\n",
    "#### Discussion on the value of the MAE\n",
    "\n",
    "#### Discussion on the predicted vs. true scatterplot\n",
    "\n",
    "#### Discussion\n",
    "\n",
    "Analyzing the scatter plot of predicted versus true values on the test set can provide insights into the model's performance:\n",
    "\n",
    "Proximity to the Diagonal:\n",
    "\n",
    "Ideally, in a well-performing model, the points should be close to the diagonal line, indicating that the predicted values are similar to the true values.\n",
    "Deviations from the diagonal suggest discrepancies between predicted and true values.\n",
    "Patterns:\n",
    "\n",
    "Look for any systematic patterns in the scatter plot. For instance, if there's a consistent trend (e.g., underestimation or overestimation) across the range of predicted values, it may indicate a bias in the model.\n",
    "Random scattering of points without a clear pattern is desirable.\n",
    "Outliers:\n",
    "\n",
    "Identify any outliers in the plot. Outliers are data points with a significant difference between predicted and true values.\n",
    "Outliers may indicate instances where the model struggled to make accurate predictions, possibly due to unusual characteristics in those data points.\n",
    "Overall Fit:\n",
    "\n",
    "Assess the overall fit of the model by considering the spread and concentration of points.\n",
    "A well-fitted model would have points evenly distributed around the diagonal, forming a tight cluster.\n",
    "Based on these considerations, you can make the following observations and conclusions:\n",
    "\n",
    "Proximity to Diagonal: If the points are close to the diagonal, it suggests that the model is making accurate predictions. If there is a noticeable deviation, it may indicate areas for improvement.\n",
    "\n",
    "Patterns: Check for any discernible patterns. For instance, if the points consistently deviate above or below the diagonal, it might suggest a systematic bias in the model.\n",
    "\n",
    "Outliers: Identify any outliers and investigate the reasons behind their large prediction errors. Outliers might be instances where the model struggled due to unique characteristics not well-captured by the features.\n",
    "\n",
    "Overall Fit: Assess whether the overall distribution of points indicates a well-fitted model. A scattered but balanced distribution around the diagonal is generally a positive sign.\n",
    "\n",
    "By critically examining these aspects of the scatter plot, you can gain valuable insights into the strengths and weaknesses of your linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81cb13",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f51f0",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "A healthcare organization is interested in understanding the relationship between the number of visits to the doctors office and certain patient characteristics. \n",
    "They have collected data on the number of visits for a sample of patients and have included the following variables\n",
    "\n",
    "* ofp : number of physician office visits\n",
    "* ofnp : number of nonphysician office visits\n",
    "* opp : number of physician outpatient visits\n",
    "* opnp : number of nonphysician outpatient visits\n",
    "* emr : number of emergency room visits\n",
    "* hosp : number of hospitalizations\n",
    "* exclhlth : the person is of excellent health (self-perceived)\n",
    "* poorhealth : the person is of poor health (self-perceived)\n",
    "* numchron : number of chronic conditions\n",
    "* adldiff : the person has a condition that limits activities of daily living ?\n",
    "* noreast : the person is from the north east region\n",
    "* midwest : the person is from the midwest region\n",
    "* west : the person is from the west region\n",
    "* age : age in years (divided by 10)\n",
    "* male : is the person male ?\n",
    "* married : is the person married ?\n",
    "* school : number of years of education\n",
    "* faminc : family income in 10000$\n",
    "* employed : is the person employed ?\n",
    "* privins : is the person covered by private health insurance?\n",
    "* medicaid : is the person covered by medicaid ?\n",
    "\n",
    "Decide which patient features are resonable to use to predict the target \"number of physician office visits\". Hint: should we really use the \"ofnp\" etc variables?\n",
    "\n",
    "Since the target variable is counts, a reasonable loss function is to consider the target variable as Poisson distributed where the parameter follows $\\lambda = \\exp(\\alpha \\cdot x + \\beta)$ where $\\alpha$ is a vector (slope) and $\\beta$ is a number (intercept). That is, the parameter is the exponential of a linear function. The reason we chose this as our parameter, is that it is always positive which is when the Poisson distribution is defined. To be specific we make the following assumption about our conditional density of $Y \\mid X$,\n",
    "$$\n",
    "    f_{Y \\mid X} (y,x) = \\frac{\\lambda^{y} e^{-\\lambda}}{y !}, \\quad \\lambda(x) = \\exp(\\alpha \\cdot x + \\beta).\n",
    "$$\n",
    "\n",
    "Recall from the lecture notes, (4.2) that in this case we should consider the log-loss (entropy) and that according to (4.2.1 Maximum Likelihood and regression) we can consider the conditional log-likelihood. Follow the steps of Example 1 and Example 2 in section (4.2) to derive the loss that needs to be minimized.\n",
    "\n",
    "Hint: when taking the log of the conditional density you will find that the term that contains the $y!$ does not depend on $\\lambda$ and as such does not depend on $\\alpha,\\beta$, it can thus be discarded. This will be essential due to numerical issues with factorials.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Load the file `data/visits_clean.csv` into the pandas dataframe `problem3_df`. Decide what should be features and target, give motivations for your choices. [3p]\n",
    "2. Create the `problem3_X` and the `problem3_y` as numpy arrays with `problem3_X` being the features and `problem3_y` being the target. Do the standard train-test split with 80% training data and 20% testing data. Store these in the variables defined in the cells. [3p]\n",
    "3. Implement $loss$ inside the class `PoissonRegression` by writing down the loss to be minimized, I have provided a formula for the $\\lambda$ that you can use. [2p]\n",
    "4. Now use the `PoissonRegression` class to train a Poisson regression model on the training data. [2p]\n",
    "5. Come up with a reasonable metric to evaluate your model on the test data, compute it and write down a justification of this. Also, interpret your result and compare it to something naive. [3p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cb526",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Let problem3_df be the pandas dataframe that contains the data from the file\n",
    "# data/visits_clean.csv\n",
    "problem3_df = XXX\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Step 1: Load data and choose features/target\n",
    "problem3_df = pd.read_csv(\"data/visits_clean.csv\")\n",
    "# Example: Assuming 'time_spent', 'num_clicks', and 'num_pages' are features, and 'visits' is the target\n",
    "features = problem3_df[['time_spent', 'num_clicks', 'num_pages']]\n",
    "target = problem3_df['visits']\n",
    "\n",
    "# Step 2: Create numpy arrays and perform train-test split\n",
    "problem3_X = features.values\n",
    "problem3_y = target.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(problem3_X, problem3_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Implement Poisson Regression Loss Function inside the class\n",
    "class PoissonRegression:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initial guess for coefficients\n",
    "        initial_coef = np.zeros(X.shape[1])\n",
    "        # Minimize the negative log-likelihood using Poisson regression loss\n",
    "        result = minimize(self.loss, initial_coef, args=(X, y), method='L-BFGS-B')\n",
    "        self.coef_ = result.x\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict using the learned coefficients\n",
    "        return np.exp(X @ self.coef_)\n",
    "\n",
    "    def loss(self, coef, X, y):\n",
    "        # Poisson regression loss (negative log-likelihood)\n",
    "        lambda_ = np.exp(X @ coef)\n",
    "        return np.sum(lambda_ - y * (X @ coef))\n",
    "\n",
    "# Step 4: Train Poisson Regression Model\n",
    "poisson_model = PoissonRegression()\n",
    "poisson_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate on test data and compute a reasonable metric\n",
    "y_pred = poisson_model.predict(X_test)\n",
    "\n",
    "# Evaluate using Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Justification for Metric:\n",
    "# Mean Absolute Error (MAE) is a suitable metric for count data prediction, providing the average absolute difference between predicted and true counts.\n",
    "\n",
    "# Interpretation of Result:\n",
    "# A lower MAE indicates better predictive performance. Compare this result to a naive baseline (e.g., mean visits) to assess the model's improvement over a simple heuristic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9674f37",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "\n",
    "problem3_features = [\"XXX\"]\n",
    "\n",
    "# Fill in the target as a string with the correct column name\n",
    "\n",
    "problem3_target = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a3bee",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "## Part 1\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 1 below this line.\n",
    "\n",
    "#### What features are reasonable?\n",
    "\n",
    "#### In regards to how much data we have, how many features do you think we should aim for?\n",
    "\n",
    "#### What other features would you like to have used but was not collected?\n",
    "\n",
    "#### Discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00cab8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# Fill in your X and y below\n",
    "problem3_X = XXX\n",
    "problem3_y = XXX\n",
    "\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8c054",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Fill in the function loss below\n",
    "\n",
    "class PoissonRegression(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        # define the objective/cost/loss function we want to minimise\n",
    "        def loss(coeffs):\n",
    "            # The parameter lambda for the given X and the proposed values \n",
    "            # of the coefficients, here coeff[:-1] represent alpha \n",
    "            # and coeff[-1] represent beta\n",
    "            lam = np.exp(np.dot(X,coeffs[:-1])+coeffs[-1])\n",
    "\n",
    "            # use the Y variable that is available here to define \n",
    "            # the loss function, return the value of the loss for \n",
    "            # this Y and for this parameter lam defined above\n",
    "            return XXX\n",
    "\n",
    "        #Use the loss above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        #this is prepared for you below\n",
    "\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1) # initial guess as 0\n",
    "        self.result = optimize.minimize(loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            return np.exp(np.dot(X,self.coeffs[:-1])+self.coeffs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e713dd9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Initialize your PoissonRegression model\n",
    "problem3_model = XXX\n",
    "\n",
    "# Fit your initialized model on the training data\n",
    "\n",
    "\n",
    "# This is to make sure that everything went well, \n",
    "# check that success is True\n",
    "print(problem3_model.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4036ed4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "# Put the computed metric value in the variable below\n",
    "problem3_metric = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd042d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "## Part 5\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line.\n",
    "\n",
    "#### Discussion on reasonable metrics and discussion about the value of the metric\n",
    "\n",
    "#### Comparison with a naive model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2022",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
